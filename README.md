# SAppEx

SAppEx (Search App for Experimenters) — это AI-сервис для **автоматизированного поиска, сегментации и анализа научных статей**.

### Поиск научных публикаций
- Источники:
  - PubMed Central (полные тексты)
  - Google Scholar (через SerpAPI)
- Автоматическое устранение дубликатов по названию и DOI
- Фильтрация по:
  - поисковому запросу
  - дате публикации
  - типу публикаций (статьи / обзоры)

---

### Семантический анализ и фильтрация
- Семантический поиск по содержанию статей
- Опциональная фильтрация по экспериментальным методикам
- Ранжирование статей по популярности авторов

---

### Обработка PDF-документов
- Автоматическое скачивание и парсинг PDF-файлов
- Корректная обработка многостолбцовых научных статей

---

### Сегментация статей на разделы
- Автоматическое выделение ключевых секций:
  - Abstract
  - Methods / Materials and Methods
  - Results
  - Discussion
- Гибридный алгоритм:
  - регулярные выражения
  - семантическое сходство на основе Sentence Transformers
- Оптимизированная векторизация с использованием **Fast Sentence Transformers (ONNX, INT8)**

---

### Экстракция экспериментальных методик (LLM)
- Извлечение структурированных экспериментальных данных с помощью LLM
- Fine-tuning модели **GPT-4o-mini** для научных текстов
- Структурированный вывод:
  - название методики
  - объект исследования
  - материалы
  - оборудование
  - пошаговая процедура
  - результаты

---

## Производительность и метрики

- Метрики сегментации:
  - **Macro Precision ≈ 89%**
  - **Macro Recall ≈ 82%**
  - **Macro F1 ≈ 85%**
- Среднее время обработки одной статьи: **4–11 секунд**
- Сокращение времени анализа литературы:
  - с **~1 недели до ~25 минут**

---

## Архитектура системы

- **Backend:** FastAPI (асинхронный)
- **Reverse Proxy:** Nginx
- **База данных:** PostgreSQL
- **ORM:** SQLAlchemy
- **Фоновые задачи и кеширование:** Redis
- **ML / NLP:**
  - Sentence Transformers (`all-MiniLM-L6-v2`)
  - Fast Sentence Transformers (ONNX, INT8)
  - Fine-tuned GPT-4o-mini
- **Развертывание:** Docker, Docker Compose

---

## Поток обработки данных

1. Пользователь отправляет поисковый запрос
2. Система собирает публикации из нескольких источников
3. PDF-файлы скачиваются и обрабатываются
4. Тексты статей сегментируются на логические разделы
5. Выполняется семантическая фильтрация и ранжирование
6. LLM извлекает структурированные экспериментальные данные
7. Пользователь получает:
   - PDF-файлы статей
   - Excel-отчет с метаданными, секциями и методиками

---

## Форматы выходных данных

- **ZIP-архив**, содержащий:
  - PDF-файлы публикаций
  - Excel-файл с:
    - метаданными статей
    - найденными секциями
    - статистикой авторов
    - извлечёнными экспериментальными методиками
- Опционально формируется **DOCX-отчет** с отобранными публикациями

---

## Технологический стек

- Python
- FastAPI
- Nginx
- PostgreSQL
- SQLAlchemy
- Redis
- SentenceTransformers
- Fast Sentence Transformers (ONNX, INT8)
- OpenAI API (fine-tuning LLM)
- Docker / Docker Compose

---

## Почему проект интересен стартапам и AI-командам

- Полноценная end-to-end AI-система
- Реальное ускорение исследовательских процессов
- Комбинация классического NLP и LLM
- Оптимизация под CPU без обязательного GPU
- Production-ready архитектура
- Практическая валидация на задачах химии и материаловедения

---

## Структура репозитория

- `parser` — сбор данных (PubMed, Google Scholar)
- `nlp` — сегментация текста и эмбеддинги
- `llm` — экстракция методик и fine-tuning
- `backend` — FastAPI сервис
- `db` — модели базы данных
- `docker` — конфигурация развертывания
